{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from paper_changes import *\n",
    "# manual feature selection\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from scipy.stats import zscore\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    '''would dod this for test, but don't want to rewrite it'''\n",
    "    def __init__(self):\n",
    "        self.recalls = list()\n",
    "        self.precisions = list()\n",
    "        self.accuracies = list()\n",
    "        self.balanced_accuracies = list()\n",
    "        self.rocs = list()\n",
    "    \n",
    "    def add_results(self, actual, preds, probs):\n",
    "        self.recalls.append(recall_score(actual, preds))\n",
    "        self.precisions.append(precision_score(actual, preds))\n",
    "        self.accuracies.append(accuracy_score(actual, preds))\n",
    "        self.balanced_accuracies.append(balanced_accuracy_score(actual, preds))\n",
    "        self.rocs.append(roc_auc_score(actual, probs))\n",
    "    \n",
    "    def avg_all(self):\n",
    "        self.avgs = pd.Series({\n",
    "            'recall': np.mean(self.recalls),\n",
    "            'precision': np.mean(self.precisions),\n",
    "            'accuracy': np.mean(self.accuracies),\n",
    "            'balanced_accuracy': np.mean(self.balanced_accuracies),\n",
    "            'roc': np.mean(self.rocs)})\n",
    "        self.recall = self.avgs.recall\n",
    "        self.precision = self.avgs.precision\n",
    "        self.accuracy = self.avgs.accuracy\n",
    "        self.balanced_accuracy = self.avgs.balanced_accuracy\n",
    "        self.roc = self.avgs.roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(X, y, pipe, get_feats, ite=100, verbose=True, null=False):\n",
    "    feats = defaultdict(list)\n",
    "    preds = list()\n",
    "    probs = list()\n",
    "    model = 'logit'\n",
    "    trm = Metrics()\n",
    "    ys = list()\n",
    "    for _ in tqdm(range(ite)) if verbose else range(ite):\n",
    "        if null:\n",
    "            y = y.sample(frac=1)\n",
    "        ys.extend(y)\n",
    "        for train_idx, test_idx in LeaveOneOut().split(X):\n",
    "            pipe.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "            trm.add_results(y.iloc[train_idx],\n",
    "                pipe.predict(X.iloc[train_idx].values), \n",
    "                pipe.predict_proba(X.iloc[train_idx].values).T[:, 1])\n",
    "            pred = pipe.predict(X.iloc[test_idx].values)[0]\n",
    "            proba = pipe.predict_proba(X.iloc[test_idx].values).T[0][1]\n",
    "            preds.append(pred)\n",
    "            probs.append(proba)\n",
    "            fs = get_feats(pipe)\n",
    "            for f in fs.index:\n",
    "                if abs(fs[f]) > 0:\n",
    "                    feats[f].append(fs[f])\n",
    "    bm = pd.DataFrame(list(zip(preds, probs, ys)), \n",
    "                      columns=['pred', 'proba', 'actual'])\n",
    "    trm.avg_all()\n",
    "    return bm, trm, feats\n",
    "\n",
    "\n",
    "def print_res(bm, trm, model='logit'):\n",
    "    rs = recall_score(bm['actual'], bm['pred'])\n",
    "    ps = precision_score(bm['actual'], bm['pred'])\n",
    "    acc = accuracy_score(bm['actual'], bm['pred'])\n",
    "    bacc = balanced_accuracy_score(bm['actual'], bm['pred'])\n",
    "    roc = roc_auc_score(bm['actual'], bm['proba'])\n",
    "    \n",
    "    results = trm.avgs.to_frame().rename(columns={0: 'train'})\n",
    "    results['test'] = 0\n",
    "    results.loc['accuracy', 'test'] = acc\n",
    "    results.loc['balanced_accuracy', 'test'] = bacc\n",
    "    results.loc['precision', 'test'] = ps\n",
    "    results.loc['recall', 'test'] = rs\n",
    "    results.loc['roc', 'test'] = roc\n",
    "    \n",
    "    print(results.round(3))\n",
    "    \n",
    "    \n",
    "def plot_res(feats):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "    fsrs['count'].apply(lambda v: v/4000).plot(kind='bar', ax=axs[0]);\n",
    "    axs[0].set_ylabel('Percent of Models w/ Feature')\n",
    "    fsrs['mean'].plot(kind='bar', yerr=fsrs['std'], ax=axs[1])\n",
    "    axs[1].set_ylabel('Avg Model Weight')\n",
    "\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   train   test\n",
      "accuracy           0.813  0.780\n",
      "balanced_accuracy  0.811  0.774\n",
      "precision          0.840  0.792\n",
      "recall             0.825  0.826\n",
      "roc                0.874  0.758\n",
      "           mean       std  count\n",
      "pc_1   0.056643  0.021148     41\n",
      "pc_10  0.391598  0.003991      2\n",
      "pc_2   0.122499  0.044751     41\n",
      "pc_3  -0.601435  0.182368     41\n",
      "pc_4   0.175330  0.107682     40\n",
      "pc_5  -0.403693  0.414317      3\n",
      "pc_6  -1.109648  0.196190     40\n",
      "pc_8   0.299287  0.000000      1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = load_data()\n",
    "\n",
    "pipe = Pipeline([('clf', LogisticRegression(C=0.75, penalty='l1', class_weight='balanced', solver='liblinear',\n",
    "                                                max_iter=100))])\n",
    "             \n",
    "get_feats = lambda pipe: pd.Series(np.squeeze(pipe.steps[-1][1].coef_), \n",
    "                                   index=['pc_' + str(i+1) for i in range(X.shape[1])])\n",
    "\n",
    "bm, trm, feats = crossval(X, y, pipe, get_feats, ite=1)\n",
    "\n",
    "print_res(bm, trm)\n",
    "\n",
    "fsrs = pd.DataFrame.from_dict({v: [np.mean(l), np.std(l), len(l)] for v, l in feats.items()},\n",
    "                              columns=['mean', 'std', 'count'], orient='index').sort_index()\n",
    "print(fsrs)\n",
    "\n",
    "plot_res(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from group_lasso import LogisticGroupLasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_to_band_group(band):\n",
    "    if 'delta' in band:\n",
    "        return 1\n",
    "    elif 'theta' in band:\n",
    "        return 2\n",
    "    elif 'alpha' in band:\n",
    "        return 3\n",
    "    elif 'beta' in band:\n",
    "        return 4\n",
    "    elif 'gammaL' in band:\n",
    "        return 5\n",
    "    elif 'gammaH' in band:\n",
    "        return 6\n",
    "    else:\n",
    "        raise ValueError('No band present')\n",
    "\n",
    "band_groups = [col_to_band_group(col) for col in X.columns]\n",
    "community_groups = [int(col[-1])+1 for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number variables: 36\n",
      "Number of chosen variables: 24\n",
      "Accuracy: 0.8048780487804879\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data()\n",
    "\n",
    "gl = LogisticGroupLasso(\n",
    "    groups=community_groups,\n",
    "    group_reg=0.01,\n",
    "    l1_reg=0.00,\n",
    ")\n",
    "\n",
    "gl.fit(X, y)\n",
    "\n",
    "pred_y = gl.predict(X.values)\n",
    "sparsity_mask = gl.sparsity_mask_\n",
    "coefs = gl.coef_[:, 1] - gl.coef_[:, 0]\n",
    "accuracy = (np.squeeze(pred_y) == y).mean()\n",
    "\n",
    "print(f\"Number variables: {len(sparsity_mask)}\")\n",
    "print(f\"Number of chosen variables: {sparsity_mask.sum()}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and unknown targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a31f0e58190b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m fsrs = pd.DataFrame.from_dict({v: [np.mean(l), np.std(l), len(l)] for v, l in feats.items()},\n",
      "\u001b[0;32m<ipython-input-3-1f9a0ab13273>\u001b[0m in \u001b[0;36mprint_res\u001b[0;34m(bm, trm, model)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actual'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actual'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actual'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/pdaly/.envs/pres/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/pdaly/.envs/pres/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \"\"\"\n\u001b[0;32m-> 1735\u001b[0;31m     _, r, _, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[1;32m   1736\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                                                  \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/pdaly/.envs/pres/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/pdaly/.envs/pres/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[1;32m   1434\u001b[0m                                     pos_label)\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/pdaly/.envs/pres/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1248\u001b[0m                          str(average_options))\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/pdaly/.envs/pres/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     91\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and unknown targets"
     ]
    }
   ],
   "source": [
    "X, y = load_data()\n",
    "\n",
    "pipe = Pipeline([('clf', LogisticGroupLasso(groups=band_groups, group_reg=0.05, l1_reg=0.05))])\n",
    "             \n",
    "get_feats = lambda pipe: pd.Series(np.squeeze(pipe.steps[-1][1].coef_[:, 1] - pipe.steps[-1][1].coef_[:, 0]), \n",
    "                                   index=X.columns)\n",
    "\n",
    "bm, trm, feats = crossval(X, y, pipe, get_feats, ite=1)\n",
    "\n",
    "print_res(bm, trm)\n",
    "\n",
    "fsrs = pd.DataFrame.from_dict({v: [np.mean(l), np.std(l), len(l)] for v, l in feats.items()},\n",
    "                              columns=['mean', 'std', 'count'], orient='index').sort_index()\n",
    "print(fsrs)\n",
    "\n",
    "plot_res(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.7073170731707317, std: 0.45499410015067393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "results = cross_validate(pipe, X.values, y, cv=LeaveOneOut())\n",
    "print(f\"mean: {results['test_score'].mean()}, std: {results['test_score'].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'group_reg': np.linspace(0, 0.05, 20), \n",
    "              'l1_reg': np.linspace(0, 0.05, 20)}\n",
    "clf = GridSearchCV(LogisticGroupLasso(groups=community_groups), param_grid=parameters,\n",
    "                   cv=LeaveOneOut())\n",
    "clf.fit(X.values, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_group_reg</th>\n",
       "      <th>param_l1_reg</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.0210526</td>\n",
       "      <td>0</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.0184211</td>\n",
       "      <td>0.00263158</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.00789474</td>\n",
       "      <td>0.00526316</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.00789474</td>\n",
       "      <td>0.00263158</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0131579</td>\n",
       "      <td>0</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0131579</td>\n",
       "      <td>0.00263158</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0131579</td>\n",
       "      <td>0.00526316</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0105263</td>\n",
       "      <td>0.00263158</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.0157895</td>\n",
       "      <td>0.00263158</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.0157895</td>\n",
       "      <td>0.00526316</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.00263158</td>\n",
       "      <td>0.00263158</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.0184211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.0157895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.0105263</td>\n",
       "      <td>0.00526316</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.0236842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.443071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.0315789</td>\n",
       "      <td>0.0157895</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.454994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.0315789</td>\n",
       "      <td>0.0184211</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.454994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.0315789</td>\n",
       "      <td>0.0210526</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.454994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.0315789</td>\n",
       "      <td>0.0236842</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.454994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.0315789</td>\n",
       "      <td>0.0263158</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.454994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_group_reg param_l1_reg  mean_test_score  std_test_score\n",
       "160       0.0210526            0         0.731707        0.443071\n",
       "141       0.0184211   0.00263158         0.731707        0.443071\n",
       "62       0.00789474   0.00526316         0.731707        0.443071\n",
       "61       0.00789474   0.00263158         0.731707        0.443071\n",
       "100       0.0131579            0         0.731707        0.443071\n",
       "101       0.0131579   0.00263158         0.731707        0.443071\n",
       "102       0.0131579   0.00526316         0.731707        0.443071\n",
       "81        0.0105263   0.00263158         0.731707        0.443071\n",
       "121       0.0157895   0.00263158         0.731707        0.443071\n",
       "122       0.0157895   0.00526316         0.731707        0.443071\n",
       "21       0.00263158   0.00263158         0.731707        0.443071\n",
       "140       0.0184211            0         0.731707        0.443071\n",
       "120       0.0157895            0         0.731707        0.443071\n",
       "82        0.0105263   0.00526316         0.731707        0.443071\n",
       "180       0.0236842            0         0.731707        0.443071\n",
       "246       0.0315789    0.0157895         0.707317        0.454994\n",
       "247       0.0315789    0.0184211         0.707317        0.454994\n",
       "248       0.0315789    0.0210526         0.707317        0.454994\n",
       "249       0.0315789    0.0236842         0.707317        0.454994\n",
       "250       0.0315789    0.0263158         0.707317        0.454994"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_) \\\n",
    "    [['param_group_reg', 'param_l1_reg', 'mean_test_score', 'std_test_score']] \\\n",
    "    .sort_values('mean_test_score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
